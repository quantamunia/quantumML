{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, jsonify, Response,request, session, current_app,redirect, url_for\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io \n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import decomposition\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit import Aer\n",
    "from qiskit import transpile, execute\n",
    "from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap, PauliFeatureMap\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.algorithms.optimizers import SPSA,COBYLA\n",
    "from qiskit_machine_learning.algorithms import VQC\n",
    "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
    "from azure.quantum import Workspace\n",
    "from azure.quantum.qiskit import AzureQuantumProvider\n",
    "from qiskit.visualization import circuit_drawer\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "objective_func_vals = []\n",
    "@app.route('/',methods=['GET', 'POST'])\n",
    "def index():\n",
    "    \n",
    " \n",
    "   \n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        model = request.form['model']\n",
    "        dataset = request.form['dataset']\n",
    "        feature_map_type = request.form['featuremap']\n",
    "        optimizer_type = request.form['optimizer']\n",
    "        split = request.form['split']\n",
    "        pca_no = request.form['pca']\n",
    "        pca_no = int(pca_no)\n",
    "        entang = request.form['entang']\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        X,y= load_dataset(dataset)\n",
    "        \n",
    "        feature_no = X.shape[1]\n",
    "        \n",
    "        X = pca(pca_no, X)\n",
    "        \n",
    "        test_size = split_ratio(split)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        \n",
    "        X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)\n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "        feature_map, ansatz, base64_feature_map_image, base64_ansatz_image = create_feature_map(feature_map_type, pca_no, entang)\n",
    "        \n",
    "        optimizer = create_optimizer(optimizer_type)    \n",
    "        \n",
    "        import threading\n",
    "        def train(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "            \n",
    "                load_model(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "            \n",
    "            \n",
    "            \n",
    "        train_thread = threading.Thread(target=train, args=(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test))\n",
    "        train_thread.start()\n",
    "        \n",
    "        return render_template('index.html',fmap=base64_feature_map_image, ans = base64_ansatz_image, dname = dataset, pcano=pca_no,\n",
    "                               ent = entang, opt = optimizer, mod = model, f_no = feature_no)\n",
    "    \n",
    "    \n",
    "       \n",
    "          \n",
    "       \n",
    "    #return redirect(url_for('index'))\n",
    "    return render_template('index.html')\n",
    "    \n",
    "def load_dataset(dataset):\n",
    "    if dataset == 'iris':\n",
    "        iris = datasets.load_iris()\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        return X, y\n",
    "    if dataset == 'diabetes':\n",
    "        diabetes = datasets.load_diabetes()\n",
    "        X = diabetes.data\n",
    "        y = diabetes.target\n",
    "        return X, y\n",
    "    if dataset == 'wine':\n",
    "        wine = datasets.load_wine()\n",
    "        X = wine.data\n",
    "        y = wine.target\n",
    "        return X, y\n",
    "    if dataset == 'cancer':\n",
    "        cancer = datasets.load_breast_cancer()\n",
    "        X = cancer.data\n",
    "        y = cancer.target\n",
    "        return X, y\n",
    "    \n",
    "def split_ratio(split):\n",
    "    if split == '80/20':\n",
    "        return 0.2\n",
    "    else :\n",
    "        return 0.3\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def draw_and_encode_circuit(circuit):\n",
    "    image_stream = io.BytesIO()\n",
    "    circuit_drawer(circuit, output=\"mpl\", fold=20, filename=image_stream)\n",
    "    image_stream.seek(0)\n",
    "    base64_image = base64.b64encode(image_stream.getvalue()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "def create_feature_map(feature_map_type, fdimension, entang):\n",
    "    if feature_map_type == 'zz':\n",
    "        # Create the ZZFeatureMap and draw its circuit\n",
    "        feature_map = ZZFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz, base64_feature_map_image, base64_ansatz_image\n",
    "    \n",
    "    elif feature_map_type == 'z':\n",
    "        # Create the ZFeatureMap and draw its circuit\n",
    "        feature_map = ZFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz,base64_feature_map_image, base64_ansatz_image\n",
    "    \n",
    "    elif feature_map_type == 'pauli':\n",
    "        # Create the ZZFeatureMap and draw its circuit\n",
    "        feature_map = PauliFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz,base64_feature_map_image, base64_ansatz_image\n",
    "\n",
    "def create_optimizer(optimizer_type):\n",
    "    if optimizer_type == 'spsa':\n",
    "        return SPSA(maxiter=100)\n",
    "    if optimizer_type == 'coby':\n",
    "        return COBYLA(maxiter=100)\n",
    "    if optimizer_type == 'adam':\n",
    "        return COBYLA(maxiter=100)\n",
    "    \n",
    "def pca(pca_no,X):\n",
    "    pca = decomposition.PCA(n_components=pca_no)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    return X   \n",
    "    \n",
    "    \n",
    "     \n",
    "#model,optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def load_model(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "   \n",
    "    if model == \"VQC/MLP\":\n",
    "        c_metrics = mlp_classifier(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = vqc_classifier(optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        \n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "        \n",
    "    \n",
    "    if model == \"QSVM/SVM\":\n",
    "        c_metrics = svm_classifier(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = qsvm_classifier(feature_map,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "        \n",
    "    \n",
    "    if model == \"QSVC/SVC\":\n",
    "        c_metrics = svc_classifie(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = qsvc_classifier(feature_map,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        bchart = barchart_mlp_vqc(c_metrics,q_metrics)\n",
    "        return bchart\n",
    "    \n",
    "    if model == \"VQC/LR\":\n",
    "        c_metrics = lr_classifie(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = vqc_classifier(optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        bchart = barchart_mlp_vqc(c_metrics,q_metrics)\n",
    "        return bchart\n",
    "\n",
    "#=============================== MLP / VQC CLASSIFIER==========================\n",
    "\n",
    "def mlp_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    # Create an instance of the MLP classifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=5000, random_state=42)\n",
    "    # Train the MLP classifier\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    # Make predictions with MLP classifier\n",
    "    y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "    # Calculate accuracy, F1 score, precision, and recall for MLP classifier\n",
    "    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    f1_mlp = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "    precision_mlp = precision_score(y_test, y_pred_mlp, average='weighted')\n",
    "    recall_mlp = recall_score(y_test, y_pred_mlp, average='weighted') \n",
    "    \n",
    "    return accuracy_mlp, f1_mlp, precision_mlp, recall_mlp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.savefig('static/graph.jpg')  # Save the graph as an image\n",
    "    plt.close()\n",
    "\n",
    "def vqc_classifier(optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    optimizer = optimizer\n",
    "    sampler = Sampler()\n",
    "    vqc = VQC(\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    "\n",
    "    )\n",
    "\n",
    "    #import threading\n",
    "    #def run_callback():\n",
    "    vqc.fit(X_train_scaled, y_train)\n",
    "\n",
    "    #train_thread = threading.Thread(target=run_callback)\n",
    "    #train_thread.start()\n",
    "    \n",
    "    # Wait for the training thread to finish\n",
    "    #train_thread.join()\n",
    "\n",
    "\n",
    "    # Make predictions with VQC\n",
    "    y_pred_vqc = vqc.predict(X_test_scaled)\n",
    "    # Calculate accuracy, F1 score, precision, and recall for VQC\n",
    "    accuracy_vqc = accuracy_score(y_test, y_pred_vqc)\n",
    "    f1_vqc = f1_score(y_test, y_pred_vqc, average='weighted')\n",
    "    precision_vqc = precision_score(y_test, y_pred_vqc, average='weighted')\n",
    "    recall_vqc = recall_score(y_test, y_pred_vqc, average='weighted')\n",
    "    print(accuracy_vqc)\n",
    "    print(f1_vqc)\n",
    "    print(precision_vqc)\n",
    "    print( recall_vqc)\n",
    "    return accuracy_vqc ,f1_vqc,precision_vqc, recall_vqc\n",
    "\n",
    "def barchart_mlp_vqc(model, c_metrics, q_metrics):\n",
    "    metrics = {}\n",
    "    quantum, classical = model.split('/')\n",
    "    # Bar chart\n",
    "    metrics['c'] = c_metrics\n",
    "    metrics['q'] = q_metrics\n",
    "    accuracy_c, f1_c, precision_c, recall_c = metrics['c']\n",
    "    accuracy_q, f1_q, precision_q, recall_q = metrics['q']\n",
    "\n",
    "    labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    c_scores = [accuracy_c, precision_c, recall_c, f1_c]\n",
    "    q_scores = [accuracy_q, precision_q, recall_q, f1_q]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, c_scores, width, label=classical)\n",
    "    rects2 = ax.bar(x + width/2, q_scores, width, label=quantum)\n",
    "\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(f'Comparison of Metrics: {classical} vs {quantum}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    ax.bar_label(rects1, padding=3)\n",
    "    ax.bar_label(rects2, padding=3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a JPG image in the static folder\n",
    "    plt.savefig('static/barchart.jpg')\n",
    "\n",
    "    # Close the plot to free up resources\n",
    "    plt.close()\n",
    " \n",
    "#================================= QSVM/SVM======================================================\n",
    "\n",
    "def svm_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    svm_pred = svm.predict(X_test_scaled)\n",
    "    \n",
    "    svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "    svm_precision = precision_score(y_test, svm_pred, average='macro')\n",
    "    svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
    "    svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
    "    print(svm_accuracy)\n",
    "    print(svm_f1)\n",
    "    print(svm_precision)\n",
    "    print( svm_recall)\n",
    "    return svm_accuracy,svm_precision, svm_recall,svm_f1\n",
    "    \n",
    "    \n",
    "def qsvm_classifier(feature_map, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    qkernel = QuantumKernel(feature_map=feature_map, quantum_instance=Aer.get_backend('qasm_simulator'))\n",
    "    qsvm = QSVC(quantum_kernel=qkernel)\n",
    "    #start = time.time()\n",
    "    #epochs = 4\n",
    "    #for _ in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "    qsvm.fit(X_train_scaled, y_train)\n",
    "    #elapsed = time.time() - start\n",
    "    # Predict labels for the test set\n",
    "    y_pred = qsvm.predict(X_test_scaled)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    qsvm_accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    qsvm_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    qsvm_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    qsvm_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(qsvm_accuracy)\n",
    "    print(qsvm_f1)\n",
    "    print(qsvm_precision)\n",
    "    print( qsvm_recall)\n",
    "    return qsvm_accuracy,qsvm_f1,qsvm_precision,qsvm_recall\n",
    "  \n",
    "\n",
    "#================================QSVC/SVC======================================================\n",
    "\n",
    "def svc_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train) \n",
    "    svc_pred = svc.predict(X_test)\n",
    "    \n",
    "    svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "    svc_precision = precision_score(y_test, svc_pred, average='macro')\n",
    "    svc_recall = recall_score(y_test, svc_pred, average='macro')\n",
    "    svc_f1 = f1_score(y_test, svc_pred, average='macro')\n",
    "    return svc_accuracy,svc_precision, svc_recall,svc_f1\n",
    "\n",
    "def qsvc_classifier(feature_map, X_train_scaled, X_test_scaled, y_train, y_test,backend):\n",
    "    sampler = Sampler()\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    qsvc = QSVC(quantum_kernel=kernel)\n",
    "    start = time.time()\n",
    "    qsvc.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    y_pred = qsvc.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    qsvc_accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    qsvc_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    qsvc_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    qsvc_recall = recall_score(y_test, y_pred, average='weighted')    \n",
    "    return qsvc_accuracy,qsvc_f1,qsvc_precision,qsvc_recall\n",
    "\n",
    "\n",
    "#================================VQC/LR======================================================\n",
    "\n",
    "\n",
    "    \n",
    "def lr_classifier():\n",
    "    # Create a logistic regression CL_model_LR\n",
    "    CL_model_LR = LogisticRegression()\n",
    "    # Train the CL_model_LR\n",
    "    CL_model_LR.fit(train_features, train_labels)\n",
    "    # Make predictions on the test set\n",
    "    y_pred_model1 = CL_model_LR.predict(test_features)\n",
    "    svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "    svc_precision = precision_score(y_test, svc_pred, average='macro')\n",
    "    svc_recall = recall_score(y_test, svc_pred, average='macro')\n",
    "    svc_f1 = f1_score(y_test, svc_pred, average='macro')\n",
    "    return svc_accuracy,svc_precision, svc_recall,svc_f1\n",
    "\n",
    "\n",
    "\n",
    "def ansatz_cir(N):\n",
    "    image_stream = io.BytesIO()\n",
    "    ansatz = RealAmplitudes(num_qubits=N, reps=3)\n",
    "    ansatz.decompose().draw(output=\"mpl\", fold=20,filename=image_stream )\n",
    "    image_stream.seek(0)\n",
    "    base64_image = base64.b64encode(image_stream.getvalue()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "    \n",
    "@app.route('/get_graph_data')\n",
    "def get_graph_data():\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 1000)\n",
    "    return jsonify({'graph_src': f'static/graph.jpg?{timestamp}'})\n",
    "\n",
    "@app.route('/get_barchart')\n",
    "def get_barchart():\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 3000)\n",
    "    return jsonify({'bar_src': f'static/barchart.jpg?{timestamp}'})\n",
    "\n",
    "\n",
    "@app.route('/quantum_job')\n",
    "def quantum_job_route():\n",
    "    if quantum_job.training_complete:\n",
    "        quantum_job.run_quantum_job() \n",
    "        quantum_job.training_complete = False\n",
    "        \n",
    "        return jsonify({'result': 'success', 'progress': 0})\n",
    "    else:\n",
    "        return jsonify({'result': 'training_in_progress', 'progress': quantum_job.progress})\n",
    "\n",
    "@app.route('/get_hist')\n",
    "def get_hist():\n",
    "     # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 4000)\n",
    "    return jsonify({'hist_src': f'static/histogram.jpg?{timestamp}'})\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5889, debug=False, use_reloader=False)   \n",
    "    \n",
    "#def connect_to_backend(backend_name):\n",
    "   # if backend_name == 'local':\n",
    "      #  return Aer.get_backend('statevector_simulator')\n",
    "   # elif backend_name == 'ionq':\n",
    "      #  provider = AzureQuantumProvider(\n",
    "          #  resource_id='/subscriptions/your_subscription_id/resourceGroups/your_resource_group/providers/Microsoft.Quantum/Workspaces/your_workspace_id',\n",
    "           # location='your_location'\n",
    "      #  )\n",
    "       # return provider.get_backend('ionq.qpu.h1')\n",
    "    # Add more backends here if needed\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98200a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
