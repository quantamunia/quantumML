{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99b606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5889\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/graph.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/barchart.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/histogram.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/graph.jpg?1690380883536 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/histogram.jpg?6761523534193 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/barchart.jpg?5071142650660 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/histogram.jpg?6761523534257 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:43] \"GET /static/barchart.jpg?5071142650732 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:45] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:45] \"GET /static/graph.jpg?1690380885574 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:46] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:46] \"GET /static/barchart.jpg?5071142659741 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:46] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:46] \"GET /static/barchart.jpg?5071142659836 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:47] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:47] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:47] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:47] \"GET /static/histogram.jpg?6761523550325 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:47] \"GET /static/graph.jpg?1690380887611 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:47] \"GET /static/histogram.jpg?6761523550460 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:49] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:49] \"GET /static/barchart.jpg?5071142668815 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:49] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:49] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:49] \"GET /static/barchart.jpg?5071142668869 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:49] \"GET /static/graph.jpg?1690380889632 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:51] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:51] \"GET /static/histogram.jpg?6761523566479 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:51] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:51] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:51] \"GET /static/histogram.jpg?6761523566559 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:51] \"GET /static/graph.jpg?1690380891646 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:52] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:52] \"GET /static/barchart.jpg?5071142677853 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:52] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:52] \"GET /static/barchart.jpg?5071142677904 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:53] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:53] \"GET /static/graph.jpg?1690380893676 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /static/barchart.jpg?5071142686909 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /static/histogram.jpg?6761523582597 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /static/barchart.jpg?5071142687019 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /static/histogram.jpg?6761523582768 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:55] \"GET /static/graph.jpg?1690380895702 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:57] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:57] \"GET /static/graph.jpg?1690380897727 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:58] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:58] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:58] \"GET /static/barchart.jpg?5071142696067 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:58] \"GET /static/barchart.jpg?5071142696174 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:59] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:59] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:59] \"GET /static/histogram.jpg?6761523598747 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:59] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:59] \"GET /static/histogram.jpg?6761523598891 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:14:59] \"GET /static/graph.jpg?1690380899743 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:01] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:01] \"GET /static/barchart.jpg?5071142705144 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:01] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:01] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:01] \"GET /static/barchart.jpg?5071142705271 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:01] \"GET /static/graph.jpg?1690380901762 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:03] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:03] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:03] \"GET /static/histogram.jpg?6761523614901 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:03] \"GET /static/histogram.jpg?6761523615015 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:03] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:03] \"GET /static/graph.jpg?1690380903768 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:04] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:04] \"GET /static/barchart.jpg?5071142714185 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:04] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:04] \"GET /static/barchart.jpg?5071142714312 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:05] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:05] \"GET /static/graph.jpg?1690380905782 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /static/barchart.jpg?5071142723238 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /static/histogram.jpg?6761523631028 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /static/histogram.jpg?6761523631073 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /static/barchart.jpg?5071142723305 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:07] \"GET /static/graph.jpg?1690380907800 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:09] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:09] \"GET /static/graph.jpg?1690380909816 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:10] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:10] \"GET /static/barchart.jpg?5071142732330 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:10] \"GET /get_barchart HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jul/2023 15:15:10] \"GET /static/barchart.jpg?5071142732429 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:11] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:11] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:11] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:11] \"GET /static/histogram.jpg?6761523647125 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:11] \"GET /static/histogram.jpg?6761523647260 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:11] \"GET /static/graph.jpg?1690380911830 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:13] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:13] \"GET /static/barchart.jpg?5071142741442 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:13] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:13] \"GET /static/barchart.jpg?5071142741487 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:13] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:13] \"GET /static/graph.jpg?1690380913847 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:15] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:15] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:15] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:15] \"GET /static/histogram.jpg?6761523663353 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:15] \"GET /static/histogram.jpg?6761523663509 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:15] \"GET /static/graph.jpg?1690380915889 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:16] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:16] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:16] \"GET /static/barchart.jpg?5071142750536 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:16] \"GET /static/barchart.jpg?5071142750626 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:17] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:17] \"GET /static/graph.jpg?1690380917927 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /static/histogram.jpg?6761523679470 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /static/barchart.jpg?5071142759635 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /static/barchart.jpg?5071142759696 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /static/histogram.jpg?6761523679647 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:19] \"GET /static/graph.jpg?1690380919951 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:21] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:21] \"GET /static/graph.jpg?1690380921976 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:22] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:22] \"GET /static/barchart.jpg?5071142768693 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:22] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:22] \"GET /static/barchart.jpg?5071142768744 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:23] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:23] \"GET /static/histogram.jpg?6761523695610 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:23] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:23] \"GET /static/histogram.jpg?6761523695740 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:23] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:24] \"GET /static/graph.jpg?1690380923990 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:25] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:25] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:25] \"GET /static/barchart.jpg?5071142777772 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:25] \"GET /static/barchart.jpg?5071142777866 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:26] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:26] \"GET /static/graph.jpg?1690380926016 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:27] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:27] \"GET /static/histogram.jpg?6761523711645 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:27] \"GET /get_hist HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:27] \"GET /static/histogram.jpg?6761523711788 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:28] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:28] \"GET /static/graph.jpg?1690380928031 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:28] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:28] \"GET /get_barchart HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:29] \"GET /static/barchart.jpg?5071142786878 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:29] \"GET /static/barchart.jpg?5071142786964 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:30] \"GET /get_graph_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 15:15:30] \"GET /static/graph.jpg?1690380930048 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, jsonify, Response,request, session, current_app,redirect, url_for\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io \n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import decomposition\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit import Aer\n",
    "from qiskit import transpile, execute\n",
    "from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap, PauliFeatureMap\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.algorithms.optimizers import SPSA,COBYLA\n",
    "from qiskit_machine_learning.algorithms import VQC\n",
    "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
    "from qiskit.algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from azure.quantum import Workspace\n",
    "from azure.quantum.qiskit import AzureQuantumProvider\n",
    "from qiskit.visualization import circuit_drawer\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "objective_func_vals = []\n",
    "@app.route('/',methods=['GET', 'POST'])\n",
    "def index():\n",
    "    \n",
    " \n",
    "   \n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        model = request.form['model']\n",
    "        dataset = request.form['dataset']\n",
    "        feature_map_type = request.form['featuremap']\n",
    "        optimizer_type = request.form['optimizer']\n",
    "        split = request.form['split']\n",
    "        pca_no = request.form['pca']\n",
    "        pca_no = int(pca_no)\n",
    "        entang = request.form['entang']\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        X,y= load_dataset(dataset)\n",
    "        \n",
    "        feature_no = X.shape[1]\n",
    "        \n",
    "        X = pca(pca_no, X)\n",
    "        \n",
    "        test_size = split_ratio(split)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        \n",
    "        X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)\n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "        feature_map, ansatz, base64_feature_map_image, base64_ansatz_image = create_feature_map(feature_map_type, pca_no, entang)\n",
    "        \n",
    "        optimizer = create_optimizer(optimizer_type)    \n",
    "        \n",
    "        import threading\n",
    "        def train(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "            \n",
    "                load_model(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "            \n",
    "            \n",
    "            \n",
    "        train_thread = threading.Thread(target=train, args=(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test))\n",
    "        train_thread.start()\n",
    "        \n",
    "        return render_template('index.html',fmap=base64_feature_map_image, ans = base64_ansatz_image, dname = dataset, pcano=pca_no,\n",
    "                               ent = entang, opt = optimizer, mod = model, f_no = feature_no)\n",
    "    \n",
    "    \n",
    "       \n",
    "          \n",
    "       \n",
    "    #return redirect(url_for('index'))\n",
    "    return render_template('index.html')\n",
    "    \n",
    "def load_dataset(dataset):\n",
    "    if dataset == 'iris':\n",
    "        iris = datasets.load_iris()\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        return X, y\n",
    "    if dataset == 'diabetes':\n",
    "        diabetes = datasets.load_diabetes()\n",
    "        X = diabetes.data\n",
    "        y = diabetes.target\n",
    "        return X, y\n",
    "    if dataset == 'wine':\n",
    "        wine = datasets.load_wine()\n",
    "        X = wine.data\n",
    "        y = wine.target\n",
    "        return X, y\n",
    "    if dataset == 'cancer':\n",
    "        cancer = datasets.load_breast_cancer()\n",
    "        X = cancer.data\n",
    "        y = cancer.target\n",
    "        return X, y\n",
    "    \n",
    "def split_ratio(split):\n",
    "    if split == '80/20':\n",
    "        return 0.2\n",
    "    else :\n",
    "        return 0.3\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def draw_and_encode_circuit(circuit):\n",
    "    image_stream = io.BytesIO()\n",
    "    circuit_drawer(circuit, output=\"mpl\", fold=20, filename=image_stream)\n",
    "    image_stream.seek(0)\n",
    "    base64_image = base64.b64encode(image_stream.getvalue()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "def create_feature_map(feature_map_type, fdimension, entang):\n",
    "    if feature_map_type == 'zz':\n",
    "        # Create the ZZFeatureMap and draw its circuit\n",
    "        feature_map = ZZFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz, base64_feature_map_image, base64_ansatz_image\n",
    "    \n",
    "    elif feature_map_type == 'z':\n",
    "        # Create the ZFeatureMap and draw its circuit\n",
    "        feature_map = ZFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz,base64_feature_map_image, base64_ansatz_image\n",
    "    \n",
    "    elif feature_map_type == 'pauli':\n",
    "        # Create the ZZFeatureMap and draw its circuit\n",
    "        feature_map = PauliFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz,base64_feature_map_image, base64_ansatz_image\n",
    "\n",
    "def create_optimizer(optimizer_type):\n",
    "    if optimizer_type == 'spsa':\n",
    "        return SPSA(maxiter=100)\n",
    "    if optimizer_type == 'coby':\n",
    "        return COBYLA(maxiter=100)\n",
    "    if optimizer_type == 'adam':\n",
    "        return COBYLA(maxiter=100)\n",
    "    \n",
    "def pca(pca_no,X):\n",
    "    pca = decomposition.PCA(n_components=pca_no)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    return X   \n",
    "    \n",
    "    \n",
    "     \n",
    "#model,optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def load_model(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "   \n",
    "    if model == \"VQC/MLP\":\n",
    "        c_metrics = mlp_classifier(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = vqc_classifier(optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test)        \n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "        \n",
    "    \n",
    "    if model == \"QSVM/SVM\":\n",
    "        c_metrics = svm_classifier(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = qsvm_classifier(feature_map,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "        \n",
    "    \n",
    "    if model == \"QSVC/SVC\":\n",
    "        c_metrics = svc_classifier(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = qsvc_classifier(feature_map,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "    \n",
    "    if model == \"VQC/LR\":\n",
    "        c_metrics = lr_classifier(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        q_metrics = vqc_classifier(optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "\n",
    "#=============================== MLP / VQC CLASSIFIER==========================\n",
    "\n",
    "def mlp_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    # Create an instance of the MLP classifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=5000, random_state=42)\n",
    "    # Train the MLP classifier\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    # Make predictions with MLP classifier\n",
    "    y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "    # Calculate accuracy, F1 score, precision, and recall for MLP classifier\n",
    "    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    f1_mlp = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "    precision_mlp = precision_score(y_test, y_pred_mlp, average='weighted')\n",
    "    recall_mlp = recall_score(y_test, y_pred_mlp, average='weighted') \n",
    "    \n",
    "    return accuracy_mlp, f1_mlp, precision_mlp, recall_mlp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.savefig('static/graph.jpg')  # Save the graph as an image\n",
    "    plt.close()\n",
    "\n",
    "def vqc_classifier(optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    optimizer = optimizer\n",
    "    sampler = Sampler()\n",
    "    vqc = VQC(\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    "\n",
    "    )\n",
    "\n",
    "    #import threading\n",
    "    #def run_callback():\n",
    "    vqc.fit(X_train_scaled, y_train)\n",
    "\n",
    "    #train_thread = threading.Thread(target=run_callback)\n",
    "    #train_thread.start()\n",
    "    \n",
    "    # Wait for the training thread to finish\n",
    "    #train_thread.join()\n",
    "\n",
    "\n",
    "    # Make predictions with VQC\n",
    "    y_pred_vqc = vqc.predict(X_test_scaled)\n",
    "    # Calculate accuracy, F1 score, precision, and recall for VQC\n",
    "    accuracy_vqc = accuracy_score(y_test, y_pred_vqc)\n",
    "    f1_vqc = f1_score(y_test, y_pred_vqc, average='weighted')\n",
    "    precision_vqc = precision_score(y_test, y_pred_vqc, average='weighted')\n",
    "    recall_vqc = recall_score(y_test, y_pred_vqc, average='weighted')\n",
    "    print(accuracy_vqc)\n",
    "    print(f1_vqc)\n",
    "    print(precision_vqc)\n",
    "    print( recall_vqc)\n",
    "    return accuracy_vqc ,f1_vqc,precision_vqc, recall_vqc\n",
    "\n",
    "def barchart_mlp_vqc(model, c_metrics, q_metrics):\n",
    "    metrics = {}\n",
    "    quantum, classical = model.split('/')\n",
    "    # Bar chart\n",
    "    metrics['c'] = c_metrics\n",
    "    metrics['q'] = q_metrics\n",
    "    accuracy_c, f1_c, precision_c, recall_c = metrics['c']\n",
    "    accuracy_q, f1_q, precision_q, recall_q = metrics['q']\n",
    "\n",
    "    labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    c_scores = [accuracy_c, precision_c, recall_c, f1_c]\n",
    "    q_scores = [accuracy_q, precision_q, recall_q, f1_q]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, c_scores, width, label=classical)\n",
    "    rects2 = ax.bar(x + width/2, q_scores, width, label=quantum)\n",
    "\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(f'Comparison of Metrics: {classical} vs {quantum}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    ax.bar_label(rects1, padding=3)\n",
    "    ax.bar_label(rects2, padding=3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot as a JPG image in the static folder\n",
    "    plt.savefig('static/barchart.jpg')\n",
    "\n",
    "    # Close the plot to free up resources\n",
    "    plt.close()\n",
    " \n",
    "#================================= QSVM/SVM======================================================\n",
    "\n",
    "def svm_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    svm_pred = svm.predict(X_test_scaled)\n",
    "    \n",
    "    svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "    svm_precision = precision_score(y_test, svm_pred, average='macro')\n",
    "    svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
    "    svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
    "    print(svm_accuracy)\n",
    "    print(svm_f1)\n",
    "    print(svm_precision)\n",
    "    print( svm_recall)\n",
    "    return svm_accuracy,svm_precision, svm_recall,svm_f1\n",
    "    \n",
    "    \n",
    "def qsvm_classifier(feature_map, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    qkernel = QuantumKernel(feature_map=feature_map, quantum_instance=Aer.get_backend('qasm_simulator'))\n",
    "    qsvm = QSVC(quantum_kernel=qkernel)\n",
    "    #start = time.time()\n",
    "    #epochs = 4\n",
    "    #for _ in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "    qsvm.fit(X_train_scaled, y_train)\n",
    "    #elapsed = time.time() - start\n",
    "    # Predict labels for the test set\n",
    "    y_pred = qsvm.predict(X_test_scaled)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    qsvm_accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    qsvm_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    qsvm_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    qsvm_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(qsvm_accuracy)\n",
    "    print(qsvm_f1)\n",
    "    print(qsvm_precision)\n",
    "    print( qsvm_recall)\n",
    "    return qsvm_accuracy,qsvm_f1,qsvm_precision,qsvm_recall\n",
    "  \n",
    "\n",
    "#================================QSVC/SVC======================================================\n",
    "\n",
    "def svc_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_scaled, y_train) \n",
    "    svc_pred = svc.predict(X_test_scaled)\n",
    "    \n",
    "    svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "    svc_precision = precision_score(y_test, svc_pred, average='macro')\n",
    "    svc_recall = recall_score(y_test, svc_pred, average='macro')\n",
    "    svc_f1 = f1_score(y_test, svc_pred, average='macro')\n",
    "    return svc_accuracy,svc_precision, svc_recall,svc_f1\n",
    "\n",
    "def qsvc_classifier(feature_map, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    sampler = Sampler()\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    qsvc = QSVC(quantum_kernel=kernel)\n",
    "    start = time.time()\n",
    "    qsvc.fit(X_train_scaled, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    y_pred = qsvc.predict(X_test_scaled)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    qsvc_accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    qsvc_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    qsvc_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    qsvc_recall = recall_score(y_test, y_pred, average='weighted')    \n",
    "    return qsvc_accuracy,qsvc_f1,qsvc_precision,qsvc_recall\n",
    "\n",
    "\n",
    "#================================VQC/LR======================================================\n",
    "\n",
    "\n",
    "    \n",
    "def lr_classifier(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    # Create a logistic regression CL_model_LR\n",
    "    lr = LogisticRegression()\n",
    "    # Train the CL_model_LR\n",
    "    lr.fit(X_train_scaled,  y_train)\n",
    "    # Make predictions on the test set\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "    lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    lr_precision = precision_score(y_test, y_pred, average='macro')\n",
    "    lr_recall = recall_score(y_test, y_pred, average='macro')\n",
    "    lr_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    return lr_accuracy,lr_precision, lr_recall,lr_f1\n",
    "\n",
    "\n",
    "\n",
    "def ansatz_cir(N):\n",
    "    image_stream = io.BytesIO()\n",
    "    ansatz = RealAmplitudes(num_qubits=N, reps=3)\n",
    "    ansatz.decompose().draw(output=\"mpl\", fold=20,filename=image_stream )\n",
    "    image_stream.seek(0)\n",
    "    base64_image = base64.b64encode(image_stream.getvalue()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "    \n",
    "@app.route('/get_graph_data')\n",
    "def get_graph_data():\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 1000)\n",
    "    return jsonify({'graph_src': f'static/graph.jpg?{timestamp}'})\n",
    "\n",
    "@app.route('/get_barchart')\n",
    "def get_barchart():\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 3000)\n",
    "    return jsonify({'bar_src': f'static/barchart.jpg?{timestamp}'})\n",
    "\n",
    "\n",
    "@app.route('/quantum_job')\n",
    "def quantum_job_route():\n",
    "    if quantum_job.training_complete:\n",
    "        quantum_job.run_quantum_job() \n",
    "        quantum_job.training_complete = False\n",
    "        \n",
    "        return jsonify({'result': 'success', 'progress': 0})\n",
    "    else:\n",
    "        return jsonify({'result': 'training_in_progress', 'progress': quantum_job.progress})\n",
    "\n",
    "@app.route('/get_hist')\n",
    "def get_hist():\n",
    "     # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 4000)\n",
    "    return jsonify({'hist_src': f'static/histogram.jpg?{timestamp}'})\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5889, debug=False, use_reloader=False)   \n",
    "    \n",
    "#def connect_to_backend(backend_name):\n",
    "   # if backend_name == 'local':\n",
    "      #  return Aer.get_backend('statevector_simulator')\n",
    "   # elif backend_name == 'ionq':\n",
    "      #  provider = AzureQuantumProvider(\n",
    "          #  resource_id='/subscriptions/your_subscription_id/resourceGroups/your_resource_group/providers/Microsoft.Quantum/Workspaces/your_workspace_id',\n",
    "           # location='your_location'\n",
    "      #  )\n",
    "       # return provider.get_backend('ionq.qpu.h1')\n",
    "    # Add more backends here if needed\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98200a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
