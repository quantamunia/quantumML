{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rahul Matai, Neha, Muta, Aldridge Abaassa, Tinoda Garapasi\n",
    "\n",
    "from flask import Flask, render_template, jsonify, Response,request, session, current_app,redirect, url_for,send_file, make_response, after_this_request\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io \n",
    "import atexit\n",
    "import os\n",
    "import seaborn as sns\n",
    "from IPython import get_ipython\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from flask_caching import Cache\n",
    "from werkzeug.serving import WSGIRequestHandler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import decomposition\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit import Aer\n",
    "from qiskit import transpile, execute\n",
    "from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap, PauliFeatureMap\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.algorithms.optimizers import SPSA,COBYLA\n",
    "from qiskit_machine_learning.algorithms import VQC\n",
    "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
    "from qiskit.algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from azure.quantum import Workspace\n",
    "from azure.quantum.qiskit import AzureQuantumProvider\n",
    "from qiskit.visualization import circuit_drawer\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SECRET_KEY'] = 'quantamunia'\n",
    "\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n",
    "class Calculations:\n",
    "    def __init__(self):\n",
    "        self.kernel_process = False\n",
    "        self.vector_process = False\n",
    "        self.var_circuit = None\n",
    "        self.training_complete = False\n",
    "        self.progress = 0\n",
    "        self.imgkill = False\n",
    "        self.tracker = False\n",
    "        \n",
    "    def model_track():\n",
    "        self.tracker = True\n",
    "        \n",
    "    def model_end():\n",
    "        self.tracker = False\n",
    "        \n",
    "    def vqc_begin(self,img_resetter):\n",
    "        if img_resetter == \"startp\":\n",
    "            self.vqc_proc = True\n",
    "            \n",
    "            \n",
    "    def vqc_end(self,img_resetter):\n",
    "        if img_resetter == \"endp\":\n",
    "            self.vqc_proc = False\n",
    "        \n",
    "        \n",
    "    def kernel_jobs(self, spinner):\n",
    "        if spinner == \"success\":\n",
    "            self.kernel_process = True\n",
    "        elif spinner == \"completed\":\n",
    "            self.vector_process = True\n",
    "                \n",
    "    def qsettings(self, var_circuit):\n",
    "        # ... your training code ...\n",
    "        self.var_circuit = var_circuit\n",
    "        self.training_complete = True\n",
    "        self.progress = 0\n",
    "        \n",
    "    def run_quantum_job(self):\n",
    "        if self.var_circuit is not None:\n",
    "            provider = AzureQuantumProvider(\n",
    "                resource_id=\"/subscriptions/e7eef170-5f0d-42c3-a6c6-9ae33096de85/resourceGroups/AzureQuantum/providers/Microsoft.Quantum/Workspaces/Quantamunia\",\n",
    "                location=\"West Europe\"\n",
    "            )\n",
    "            provider.backends()\n",
    "            backend = provider.get_backend(\"ionq.simulator\")\n",
    "            params = self.var_circuit.parameters\n",
    "            random_values = [random.uniform(0, 2 * np.pi) for _ in range(len(params))]\n",
    "            bound_circuit = self.var_circuit.bind_parameters(dict(zip(params, random_values)))\n",
    "            total_iterations = 10\n",
    "            progress_values = []\n",
    "            job = execute(bound_circuit, backend=backend)\n",
    "            result = job.result()\n",
    "            counts = result.get_counts()     \n",
    "           \n",
    "            fig = plot_histogram(counts)\n",
    "            fig.text(0.5, 0.95, 'Circuit Histogram', ha='center', fontsize=12)\n",
    "            \n",
    "            \n",
    "            \n",
    "            temp_folder = os.path.join(app.static_folder,  temp_folder_name)\n",
    "            os.makedirs(temp_folder, exist_ok=True)\n",
    "            # Save the graph in the temporary folder\n",
    "            graph_path = os.path.join(temp_folder, 'histogram.jpg')\n",
    "            fig.savefig(graph_path)\n",
    "            plt.close(fig)\n",
    "            \n",
    "              \n",
    "         \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "\n",
    "spinObj = Calculations()\n",
    "azureJob = Calculations()\n",
    "vqcObj = Calculations()\n",
    "imgCleaner = Calculations()\n",
    "\n",
    "\n",
    "\n",
    "objective_func_vals = []\n",
    "temp_folder_name = None\n",
    "\n",
    "def delete_temp_folder():\n",
    "    global temp_folder_name\n",
    "    if temp_folder_name is not None:\n",
    "        temp_folder_path = os.path.join(app.static_folder, temp_folder_name)\n",
    "        if os.path.exists(temp_folder_path):\n",
    "            shutil.rmtree(temp_folder_path)\n",
    "    temp_folder_name = None  # Reset the temp_folder_name variable\n",
    "\n",
    "def generate_temp_folder():\n",
    "    global temp_folder_name\n",
    "    if temp_folder_name is None:\n",
    "        temp_folder_name = next(tempfile._get_candidate_names())\n",
    "        \n",
    "@app.before_request\n",
    "def before_request():\n",
    "    generate_temp_folder()\n",
    "    \n",
    "\n",
    "@app.route('/',methods=['GET', 'POST'])\n",
    "def index():\n",
    "    \n",
    "   # session['temp_folder_name'] = temp_folder_name\n",
    "   \n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        model = request.form['model']\n",
    "        dataset = request.form['dataset']\n",
    "        feature_map_type = request.form['featuremap']\n",
    "        optimizer_type = request.form['optimizer']\n",
    "        max_iter = request.form['max_iter']\n",
    "        split = request.form['split']\n",
    "        pca_no = request.form['pca']\n",
    "        pca_no = int(pca_no)\n",
    "        entang = request.form['entang']\n",
    "       \n",
    "      \n",
    "        \n",
    "        \n",
    "        X,y,dset= load_dataset(dataset)\n",
    "        \n",
    "        feature_no = X.shape[1]\n",
    "       \n",
    "        X = pca(pca_no, X)\n",
    "        \n",
    "        test_size = split_ratio(split)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        \n",
    "        X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)\n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "        feature_map, ansatz, base64_feature_map_image, base64_ansatz_image = create_feature_map(feature_map_type, pca_no, entang)\n",
    "        \n",
    "        optimizer, optname = create_optimizer(optimizer_type,max_iter)    \n",
    "        \n",
    "        import threading\n",
    "        def train(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "            \n",
    "                load_model(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "            \n",
    "            \n",
    "            \n",
    "        train_thread = threading.Thread(target=train, args=(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test,dset))\n",
    "        train_thread.start()\n",
    "        \n",
    "        return render_template('index.html',fmap=base64_feature_map_image, ans = base64_ansatz_image, dname = dataset, pcano=pca_no,\n",
    "                               ent = entang, opt = optname, mod = model, f_no = pca_no)\n",
    "    \n",
    "    \n",
    "       \n",
    "          \n",
    "       \n",
    "    #return redirect(url_for('index'))\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "    \n",
    "def load_dataset(dataset):\n",
    "    if dataset == 'iris':\n",
    "        iris = datasets.load_iris()\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        return X, y, iris\n",
    "    if dataset == 'diabetes':\n",
    "        diabetes = datasets.load_diabetes()\n",
    "        X = diabetes.data\n",
    "        y = diabetes.target\n",
    "        return X, y,diabetes\n",
    "    if dataset == 'wine':\n",
    "        wine = datasets.load_wine()\n",
    "        X = wine.data\n",
    "        y = wine.target\n",
    "        return X, y,wine\n",
    "    if dataset == 'cancer':\n",
    "        cancer = datasets.load_breast_cancer()\n",
    "        X = cancer.data\n",
    "        y = cancer.target\n",
    "        return X, y,cancer\n",
    "    \n",
    "def split_ratio(split):\n",
    "    if split == '80/20':\n",
    "        return 0.2\n",
    "    else :\n",
    "        return 0.3\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def draw_and_encode_circuit(circuit):\n",
    "    image_stream = io.BytesIO()\n",
    "    circuit_drawer(circuit, output=\"mpl\", fold=20, filename=image_stream)\n",
    "    image_stream.seek(0)\n",
    "    base64_image = base64.b64encode(image_stream.getvalue()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "def create_feature_map(feature_map_type, fdimension, entang):\n",
    "    if feature_map_type == 'zz':\n",
    "        # Create the ZZFeatureMap and draw its circuit\n",
    "        feature_map = ZZFeatureMap(feature_dimension=fdimension, reps=2, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz, base64_feature_map_image, base64_ansatz_image\n",
    "    \n",
    "    elif feature_map_type == 'z':\n",
    "        # Create the ZFeatureMap and draw its circuit\n",
    "        feature_map = ZFeatureMap(feature_dimension=fdimension, reps=1)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz,base64_feature_map_image, base64_ansatz_image\n",
    "    \n",
    "    elif feature_map_type == 'pauli':\n",
    "        # Create the ZZFeatureMap and draw its circuit\n",
    "        feature_map = PauliFeatureMap(feature_dimension=fdimension, reps=1, entanglement=entang)\n",
    "        base64_feature_map_image = draw_and_encode_circuit(feature_map.decompose())\n",
    "\n",
    "        # Create the RealAmplitudes ansatz and draw its circuit\n",
    "        ansatz = RealAmplitudes(num_qubits=fdimension, reps=3)\n",
    "        base64_ansatz_image = draw_and_encode_circuit(ansatz.decompose())\n",
    "\n",
    "        return feature_map,ansatz,base64_feature_map_image, base64_ansatz_image\n",
    "\n",
    "def create_optimizer(optimizer_type,max_iter):\n",
    "    if optimizer_type == 'spsa':\n",
    "        return SPSA(maxiter=max_iter), \"SPSA\"\n",
    "    elif optimizer_type == 'cobyla':\n",
    "        return COBYLA(maxiter=max_iter), \"COBYLA\"\n",
    "    elif optimizer_type == 'adam':\n",
    "        return COBYLA(maxiter=max_iter), \"ADAM\"\n",
    "    else:\n",
    "        return \"NONE\", \"NONE\"\n",
    "    \n",
    "def pca(pca_no,X):\n",
    "    pca = decomposition.PCA(n_components=pca_no)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    return X   \n",
    "    \n",
    "    \n",
    "     \n",
    "#model,optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def load_model(model,optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "   \n",
    "    if model == \"VQC/MLP\":\n",
    "        imgCleaner.imgkill = True\n",
    "        c_metrics = mlp_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        q_metrics = vqc_classifier(optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test,dset)        \n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "        \n",
    "    \n",
    "    if model == \"QSVM/SVM\":\n",
    "        imgCleaner.imgkill = True\n",
    "        c_metrics = svm_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        q_metrics = qsvm_classifier(feature_map,X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "        \n",
    "    \n",
    "    if model == \"QSVC/SVC\":\n",
    "        imgCleaner.imgkill = True\n",
    "        c_metrics = svc_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        q_metrics = qsvc_classifier(feature_map,X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "    \n",
    "    if model == \"VQC/LR\":\n",
    "        imgCleaner.imgkill = True\n",
    "        c_metrics = lr_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        q_metrics = vqc_classifier(optimizer,feature_map,ansatz,X_train_scaled, X_test_scaled, y_train, y_test,dset)\n",
    "        barchart_mlp_vqc(model,c_metrics,q_metrics)\n",
    "\n",
    "#=============================== MLP / VQC CLASSIFIER==========================\n",
    "\n",
    "\n",
    "def mlp_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "    \n",
    "    # Create an instance of the MLP classifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=4000, random_state=42)\n",
    "    # Train the MLP classifier\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    # Make predictions with MLP classifier\n",
    "    y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "    # Calculate accuracy, F1 score, precision, and recall for MLP classifier\n",
    "    cm = confusion_matrix(y_test, y_pred_mlp)\n",
    "    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    f1_mlp = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "    precision_mlp = precision_score(y_test, y_pred_mlp, average='weighted')\n",
    "    recall_mlp = recall_score(y_test, y_pred_mlp, average='weighted') \n",
    "    class_name = \"MLP\"\n",
    "    imgCleaner.imgkill = False\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename='cc_matrix.jpg')\n",
    "    print(accuracy_mlp)\n",
    "    print(precision_mlp)\n",
    "    print(recall_mlp)\n",
    "    print(f1_mlp)\n",
    "    return accuracy_mlp, f1_mlp, precision_mlp, recall_mlp\n",
    "\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\", fontweight=\"bold\", fontsize=13, y=1.05)\n",
    "    plt.xlabel(\"Iteration\", fontsize=12)\n",
    "    plt.ylabel(\"Objective function value\",fontsize=12)\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    # Generate a timestamp\n",
    "    #timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    # Append the timestamp to the filename\n",
    "    #filename = f'static/graph_{timestamp}.jpg'\n",
    "    #plt.savefig('static/graph.jpg')  # Save the graph as an image\n",
    "    #plt.close()\n",
    "    # Generate a random name for the temporary folder\n",
    "    # Retrieve the temporary folder name from the session\n",
    "    # Create the temporary folder inside the static folder\n",
    "    temp_folder = os.path.join(app.static_folder,  temp_folder_name)\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "    # Save the graph in the temporary folder\n",
    "    graph_path = os.path.join(temp_folder, 'graph.jpg')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.savefig(graph_path)  # Save the graph as an image\n",
    "    plt.close()\n",
    "    return graph_path\n",
    "    \n",
    "#def tooo():\n",
    "    #print('hello')\n",
    "\n",
    "def vqc_classifier(optimizer,feature_map,ansatz, X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "    objective_func_vals.clear()\n",
    "   \n",
    "    #vqcObj.vqc_begin(\"startp\")\n",
    "    sampler = Sampler()\n",
    "    vqc = VQC(\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    "\n",
    "    )\n",
    "   \n",
    "    #import threading\n",
    "    #def run_callback():\n",
    "    vqc.fit(X_train_scaled, y_train)\n",
    "\n",
    "    #train_thread = threading.Thread(target=run_callback)\n",
    "    #train_thread.start()\n",
    "    \n",
    "    # Wait for the training thread to finish\n",
    "    #train_thread.join()\n",
    "\n",
    "    \n",
    "    # Make predictions with VQC\n",
    "    y_pred_vqc = vqc.predict(X_test_scaled)\n",
    "    # Calculate accuracy, F1 score, precision, and recall for VQC\n",
    "    cm = confusion_matrix(y_test, y_pred_vqc)\n",
    "    accuracy_vqc = accuracy_score(y_test, y_pred_vqc)\n",
    "    f1_vqc = f1_score(y_test, y_pred_vqc, average='weighted')\n",
    "    precision_vqc = precision_score(y_test, y_pred_vqc, average='weighted')\n",
    "    recall_vqc = recall_score(y_test, y_pred_vqc, average='weighted')\n",
    "    print(accuracy_vqc)\n",
    "    print(f1_vqc)\n",
    "    print(precision_vqc)\n",
    "    print( recall_vqc)\n",
    "    spinner = \"completed\"\n",
    "    spinObj.kernel_jobs(spinner)\n",
    "    class_name = \"VQC\"\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename='qc_matrix.jpg')\n",
    "    #vqcObj.vqc_end(\"endp\")\n",
    "    azureJob.qsettings(vqc.circuit)\n",
    "    return accuracy_vqc ,f1_vqc,precision_vqc, recall_vqc\n",
    "\n",
    "def barchart_mlp_vqc(model, c_metrics, q_metrics):\n",
    "    metrics = {}\n",
    "    quantum, classical = model.split('/')\n",
    "    # Bar chart\n",
    "    metrics['c'] = c_metrics\n",
    "    metrics['q'] = q_metrics\n",
    "    accuracy_c, f1_c, precision_c, recall_c = metrics['c']\n",
    "    accuracy_q, f1_q, precision_q, recall_q = metrics['q']\n",
    "    accuracy_c = round(accuracy_c,2)\n",
    "    f1_c=round(f1_c,2)\n",
    "    precision_c=round(precision_c,2)\n",
    "    recall_c=round(recall_c,2)\n",
    "    accuracy_q = round(accuracy_q,2)\n",
    "    f1_q=round(f1_q,2)\n",
    "    precision_q=round(precision_q,2)\n",
    "    recall_q=round(recall_q,2)\n",
    "    labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    c_scores = [accuracy_c, precision_c, recall_c, f1_c]\n",
    "    q_scores = [accuracy_q, precision_q, recall_q, f1_q]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, c_scores, width, label=classical)\n",
    "    rects2 = ax.bar(x + width/2, q_scores, width, label=quantum)\n",
    "    ax.margins(y=0.15)\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(f'Comparison of Metrics: {classical} vs {quantum}', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "    ax.bar_label(rects1, padding=3)\n",
    "    ax.bar_label(rects2, padding=3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_folder = os.path.join(app.static_folder,  temp_folder_name)\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "    # Save the graph in the temporary folder\n",
    "    graph_path = os.path.join(temp_folder, 'barchart.jpg')\n",
    "    # Save the plot as a JPG image in the static folder\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.savefig('static/barchart.jpg')\n",
    "    plt.savefig(graph_path)\n",
    "    # Close the plot to free up resources\n",
    "    plt.close()\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#================================= QSVM/SVM======================================================\n",
    "\n",
    "def svm_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "    \n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    svm_pred = svm.predict(X_test_scaled)\n",
    "    \n",
    "    \n",
    "  \n",
    "    cm = confusion_matrix(y_test, svm_pred)\n",
    "    svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "    svm_precision = precision_score(y_test, svm_pred, average='macro')\n",
    "    svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
    "    svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
    "    print(svm_accuracy)\n",
    "    print(svm_f1)\n",
    "    print(svm_precision)\n",
    "    print( svm_recall)\n",
    "    class_name = \"SVM\"\n",
    "    imgCleaner.imgkill = False\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename=\"cc_matrix.jpg\")\n",
    "    return svm_accuracy,svm_precision, svm_recall,svm_f1\n",
    "    \n",
    "    \n",
    "def qsvm_classifier(feature_map, X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "   \n",
    "    qkernel = QuantumKernel(feature_map=feature_map, quantum_instance=Aer.get_backend('qasm_simulator'))\n",
    "    qsvm = QSVC(quantum_kernel=qkernel)\n",
    "    #start = time.time()\n",
    "    #epochs = 4\n",
    "    #for _ in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "    qsvm.fit(X_train_scaled, y_train)\n",
    "    #elapsed = time.time() - start\n",
    "    # Predict labels for the test set\n",
    "    y_pred = qsvm.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "   \n",
    "    qsvm_accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    qsvm_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    qsvm_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    qsvm_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(qsvm_accuracy)\n",
    "    print(qsvm_f1)\n",
    "    print(qsvm_precision)\n",
    "    print( qsvm_recall)\n",
    "    spinner = \"success\"\n",
    "    spinObj.kernel_jobs(spinner)\n",
    "    class_name = \"QSVM\"\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename=\"qc_matrix.jpg\")\n",
    "    return qsvm_accuracy,qsvm_f1,qsvm_precision,qsvm_recall\n",
    "  \n",
    "\n",
    "#================================QSVC/SVC======================================================\n",
    "\n",
    "def svc_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_scaled, y_train) \n",
    "    svc_pred = svc.predict(X_test_scaled)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, svc_pred)\n",
    "    svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "    svc_precision = precision_score(y_test, svc_pred, average='macro')\n",
    "    svc_recall = recall_score(y_test, svc_pred, average='macro')\n",
    "    svc_f1 = f1_score(y_test, svc_pred, average='macro')\n",
    "    imgCleaner.imgkill = False\n",
    "    class_name = \"SVC\"\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename=\"cc_matrix.jpg\")\n",
    "    return svc_accuracy,svc_precision, svc_recall,svc_f1\n",
    "\n",
    "def qsvc_classifier(feature_map, X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "    \n",
    "    sampler = Sampler()\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    qsvc = QSVC(quantum_kernel=kernel)\n",
    "    #start = time.time()\n",
    "    qsvc.fit(X_train_scaled, y_train)\n",
    "    #elapsed = time.time() - start\n",
    "    y_pred = qsvc.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    qsvc_accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    qsvc_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    qsvc_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    qsvc_recall = recall_score(y_test, y_pred, average='weighted')  \n",
    "    spinner = \"success\"\n",
    "    spinObj.kernel_jobs(spinner)\n",
    "    class_name = \"QSVC\"\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename=\"qc_matrix.jpg\")\n",
    "    return qsvc_accuracy,qsvc_f1,qsvc_precision,qsvc_recall\n",
    "\n",
    "\n",
    "#================================VQC/LR======================================================\n",
    "\n",
    "\n",
    "    \n",
    "def lr_classifier(X_train_scaled, X_test_scaled, y_train, y_test,dset):\n",
    "    # Create a logistic regression CL_model_LR\n",
    "    lr = LogisticRegression()\n",
    "    # Train the CL_model_LR\n",
    "    lr.fit(X_train_scaled,  y_train)\n",
    "    # Make predictions on the test set\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    lr_precision = precision_score(y_test, y_pred, average='macro')\n",
    "    lr_recall = recall_score(y_test, y_pred, average='macro')\n",
    "    lr_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    class_name = \"LR\"\n",
    "    imgCleaner.imgkill = False\n",
    "    plot_confusion_matrix(cm, title=f'Confusion Matrix for {class_name}', classes=dset.target_names, filename=\"cc_matrix.jpg\")\n",
    "    return lr_accuracy,lr_precision, lr_recall,lr_f1\n",
    "\n",
    "\n",
    "\n",
    "# Create a function to display the confusion matrix in a smaller size\n",
    "def plot_confusion_matrix(cm, title, classes, filename):\n",
    "  \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_folder = os.path.join(app.static_folder,  temp_folder_name)\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "    # Save the graph in the temporary folder\n",
    "    graph_path = os.path.join(temp_folder, filename)\n",
    "    # Save the plot as a JPG image in the static folder\n",
    "    \n",
    "    \n",
    "    plt.savefig(graph_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def ansatz_cir(N):\n",
    "    image_stream = io.BytesIO()\n",
    "    ansatz = RealAmplitudes(num_qubits=N, reps=3)\n",
    "    ansatz.decompose().draw(output=\"mpl\", fold=20,filename=image_stream )\n",
    "    image_stream.seek(0)\n",
    "    base64_image = base64.b64encode(image_stream.getvalue()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "    \n",
    "#@app.route('/get_graph_data')\n",
    "\n",
    "#def get_graph_data():   \n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    #timestamp = int(time.time() * 1000)\n",
    "    #return jsonify({'graph_src': f'static/temp/graph.jpg?{timestamp}'})\n",
    "\n",
    "#@app.route('/get_graph_data')\n",
    "#def get_graph_data():\n",
    "    #timestamp = int(time.time() * 1000)\n",
    "    #graph_path = callback_graph()\n",
    "    #return jsonify({'graph_src': graph_path})\n",
    "    \n",
    "    \n",
    "@app.route('/get_graph_data')\n",
    "def get_graph_data():\n",
    "    #temp_folder_name = session.get('temp_folder_name')\n",
    "    # Construct the path to the graph image\n",
    "    graph_path = os.path.join('static', temp_folder_name, 'graph.jpg')\n",
    "   \n",
    "    timestamp = int(time.time() * 1000)\n",
    "    # Return the graph image path as JSON\n",
    "    return jsonify({'graph_src': f\"{graph_path}?{timestamp}\"})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/get_barchart')\n",
    "def get_barchart():\n",
    "    #temp_folder_name = session.get('temp_folder_name')\n",
    "     # Construct the path to the graph image\n",
    "    graph_path = os.path.join('static', temp_folder_name, 'barchart.jpg')\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 1500)\n",
    "    #return jsonify({'bar_src': f'static/barchart.jpg?{timestamp}'})\n",
    "    return jsonify({'bar_src': f\"{graph_path}?{timestamp}\"})\n",
    "\n",
    "@app.route('/get_cc_matrix')\n",
    "def get_cc_matrix():\n",
    "    #temp_folder_name = session.get('temp_folder_name')\n",
    "    # Construct the path to the graph image\n",
    "    graph_path = os.path.join('static', temp_folder_name, 'cc_matrix.jpg')\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 2000)\n",
    "    #return jsonify({'bar_src': f'static/cc_matrix.jpg?{timestamp}'})\n",
    "    return jsonify({'bar_src': f\"{graph_path}?{timestamp}\"})\n",
    "\n",
    "@app.route('/get_qc_matrix')\n",
    "def get_qc_matrix():\n",
    "    #temp_folder_name = session.get('temp_folder_name')\n",
    "    # Construct the path to the graph image\n",
    "    graph_path = os.path.join('static', temp_folder_name, 'qc_matrix.jpg')\n",
    "    # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 2500)\n",
    "    #return jsonify({'bar_src': f'static/qc_matrix.jpg?{timestamp}'})\n",
    "    return jsonify({'bar_src': f\"{graph_path}?{timestamp}\"})\n",
    "\n",
    "@app.route('/quantum_job')\n",
    "def quantum_job_route():\n",
    "    if azureJob.training_complete:\n",
    "        \n",
    "        azureJob.run_quantum_job()\n",
    "        azureJob.training_complete = False\n",
    "        \n",
    "       \n",
    "        return jsonify({'result': 'success', 'progress': 0})\n",
    "    else:\n",
    "        return jsonify({'result': 'training_in_progress', 'progress': azureJob.progress})\n",
    "\n",
    "\n",
    "@app.route('/get_hist')\n",
    "def get_hist():\n",
    "    #temp_folder_name = session.get('temp_folder_name')\n",
    "    # Construct the path to the graph image\n",
    "    graph_path = os.path.join('static', temp_folder_name, 'histogram.jpg')\n",
    "     # Return the current timestamp as a unique parameter to prevent caching\n",
    "    timestamp = int(time.time() * 4000)\n",
    "    #return jsonify({'hist_src': f'static/histogram.jpg?{timestamp}'})\n",
    "    return jsonify({'hist_src': f\"{graph_path}?{timestamp}\"})\n",
    "\n",
    "@app.route('/q_spinner')\n",
    "def q_spinner():\n",
    "    if spinObj.vector_process:\n",
    "        qvector =  \"completed\"\n",
    "        spinObj.vector_process = False\n",
    "        return jsonify({\"spinner\": qvector})\n",
    "    \n",
    "    if spinObj.kernel_process:\n",
    "        spinner = \"success\"\n",
    "        spinObj.kernel_process = False\n",
    "        return jsonify({\"spinner\": spinner})\n",
    "    else:\n",
    "        spinner = \"training\"\n",
    "        return jsonify({\"spinner\": spinner})\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "@app.route('/img_kill')   \n",
    "def img_kill():\n",
    "    \n",
    "    if imgCleaner.imgkill == True:\n",
    "        \n",
    "        @after_this_request\n",
    "        def add_cache_control(response):\n",
    "            response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'\n",
    "            response.headers['Pragma'] = 'no-cache'\n",
    "            response.headers['Expires'] = '0'\n",
    "            return response\n",
    "        \n",
    "        static_folder = os.path.join('static', temp_folder_name)\n",
    "        extensions_to_delete = ['.jpg', '.png']\n",
    "        for filename in os.listdir(static_folder):\n",
    "            if any(filename.lower().endswith(ext) for ext in extensions_to_delete):\n",
    "                file_path = os.path.join(static_folder, filename)\n",
    "                os.remove(file_path)\n",
    "        #redirect(url_for('index.html'))\n",
    "        \n",
    "        return jsonify({'message': 'deleted'})\n",
    "    else:\n",
    "        return jsonify({'message': 'not deleting'})\n",
    "        \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    #atexit.register(img_kill)\n",
    "    app.run(port=5889, debug=False, use_reloader=False)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16f4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
